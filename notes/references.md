# REFERENCES IN PAPERS

<a name="1" />

[1] S. Song and J. Xiao. Sliding Shapes for 3D object detection in RGB-D images. In ECCV, 2014. [back](https://github.com/aktumar/3D_reconstruction/blob/main/additional_info/notes/papers/3D_ShapeNets.md#1)

<a name="2" />

[2] S. Chaudhuri, E. Kalogerakis, L. Guibas, and V. Koltun. Probabilistic reasoning for assembly-based 3d modeling. In ACM Transactions on Graphics (TOG), 2011. [back](https://github.com/aktumar/3D_reconstruction/blob/main/additional_info/notes/papers/3D_ShapeNets.md#2)

[3] E. Kalogerakis, S. Chaudhuri, D. Koller, and V. Koltun. A probabilistic model for component-based shape synthesis. ACM Transactions on Graphics (TOG), 2012. [back](https://github.com/aktumar/3D_reconstruction/blob/main/additional_info/notes/papers/3D_ShapeNets.md#2)

[4] C.-H. Shen, H. Fu, K. Chen, and S.-M. Hu. Structure recovery by part assembly. ACM Transactions on Graphics (TOG), 2012. [back](https://github.com/aktumar/3D_reconstruction/blob/main/additional_info/notes/papers/3D_ShapeNets.md#2)

<a name="3" />

[5] P. K. Nathan Silberman, Derek Hoiem and R. Fergus. Indoor segmentation and support inference from rgbd images. In ECCV, 2012. [back](https://github.com/aktumar/3D_reconstruction/blob/main/additional_info/notes/papers/3D_ShapeNets.md.md#3)

<a name="4"/> 

[6] M. Attene. A lightweight approach to repairing digitized polygon meshes. The Visual Computer, 2010. [back](https://github.com/aktumar/3D_reconstruction/blob/main/additional_info/notes/papers/3D_ShapeNets.md#4)

[7] S. Shalom, A. Shamir, H. Zhang, and D. Cohen-Or. Cone carving for surface reconstruction. In ACM Transactions on Graphics (TOG), 2010. [back](https://github.com/aktumar/3D_reconstruction/blob/main/additional_info/notes/papers/3D_ShapeNets.md#4)

<a name="5"/> 

[8] R. Socher, B. Huval, B. Bhat, C. D. Manning, and A. Y. Ng. Convolutional-recursive deep learning for 3d object classification. In NIPS. 2012. [back](https://github.com/aktumar/3D_reconstruction/blob/main/additional_info/notes/papers/3D_ShapeNets.md#5)

[9] S. Gupta, R. Girshick, P. Arbelaez, and J. Malik. Learning ´ rich features from rgb-d images for object detection and segmentation. In ECCV. 2014. [back](https://github.com/aktumar/3D_reconstruction/blob/main/additional_info/notes/papers/3D_ShapeNets.md#5)

<a name="6"/>

[10] F. G. Callari and F. P. Ferrie. Active object recognition: Looking for differences. IJCV, 2001. [back](https://github.com/aktumar/3D_reconstruction/blob/main/additional_info/notes/papers/3D_ShapeNets.md#6)

<a name="7"/>

[11] G. E. Hinton, S. Osindero, and Y.-W. Teh. A fast learning algorithm for deep belief nets. Neural computation, 2006. [back](https://github.com/aktumar/3D_reconstruction/blob/main/additional_info/notes/papers/3D_ShapeNets.md#7)

<a name="8"/>

[12] James Coughlan, Alan Yuille. Manhattan World: Orientation and Outlier Detection by Bayesian Inference. Submitted to Neural Computation. 2003. [[link](https://www.cs.jhu.edu/~ayuille/pubs/ucla/A179_jcoughlan_NC2003.pdf)] [back](https://github.com/aktumar/3D_reconstruction/blob/main/additional_info/notes/youtube/Learning_3D_Rec_in_Function_Space.md)

<a name="9"/>

[13] P. Shilane, P. Min, M. Kazhdan, and T. Funkhouser. The princeton shape benchmark. In Shape Modeling Applications, 2004. [back](https://github.com/aktumar/3D_reconstruction/blob/main/additional_info/notes/papers/3D_ShapeNets.md#9)

[14] J. Xiao, J. Hays, K. A. Ehinger, A. Oliva, and A. Torralba. SUN database: Large-scale scene recognition from abbey to zoo. In CVPR, 2010. [back](https://github.com/aktumar/3D_reconstruction/blob/main/additional_info/notes/papers/3D_ShapeNets.md#9)

[15] P. Shilane, P. Min, M. Kazhdan, and T. Funkhouser. The princeton shape benchmark. In Shape Modeling Applications, 2004. [back](https://github.com/aktumar/3D_reconstruction/blob/main/additional_info/notes/papers/3D_ShapeNets.md#9)

<a name="10"/>

[16] P. J. Besl and N. D. McKay. Method for registration of 3-d shapes. In PAMI, 1992. [back](https://github.com/aktumar/3D_reconstruction/blob/main/additional_info/notes/papers/3D_ShapeNets.md#10)

<a name="11"/>

[17] B. Li, C. Shen, Y. Dai, A. Van Den Hengel, and M. He, “Depth and surface normal estimation from monocular images using regression on deep features and hierarchical CRFs,” in IEEE CVPR, 2015, pp. 1119–1127.

[18] D. Eigen and R. Fergus, “Predicting depth, surface normals and semantic labels with a common multi-scale convolutional architecture,” in IEEE ICCV, 2015, pp. 2650–2658.

[19] R. Garg, V. K. BG, G. Carneiro, and I. Reid, “Unsupervised CNN for single view depth estimation: Geometry to the rescue,” in ECCV, 2016, pp. 740–756.

[20] F. Liu, C. Shen, G. Lin, and I. D. Reid, “Learning Depth from Single Monocular Images Using Deep Convolutional Neural Fields,” IEEE PAMI, vol. 38, no. 10, pp. 2024–2039, 2016.

<a name="12"/>

[21] J. Yang, S. E. Reed, M.-H. Yang, and H. Lee, “Weakly-supervised disentangling with recurrent transformations for 3D view synthesis,” in NIPS, 2015, pp. 1099–1107.

[22] T. D. Kulkarni, W. F. Whitney, P. Kohli, and J. Tenenbaum, “Deep convolutional inverse graphics network,” in NIPS, 2015, pp. 2539–2547.

[23] M. Tatarchenko, A. Dosovitskiy, and T. Brox, “Multi-view 3D models from single images with a convolutional network,” in ECCV, 2016, pp. 322–337.

[24] T. Zhou, S. Tulsiani, W. Sun, J. Malik, and A. A. Efros, “View synthesis by appearance ﬂow,” in ECCV, 2016, pp. 286–301.

[25] E. Park, J. Yang, E. Yumer, D. Ceylan, and A. C. Berg, “Transformation-grounded image generation network for novel 3D view synthesis,” in IEEE CVPR, 2017, pp. 702–711.

<a name="13"/>

[26] D. Scharstein and R. Szeliski, “A taxonomy and evaluation of dense two-frame stereo correspondence algorithms,” IJCV, vol. 47, no. 1-3, pp. 7–42, 2002.

<a name="14"/>

[27] Yu Zhong , “Intrinsic Shape Signatures: A Shape Descriptor for 3D Object Recognition”, 2009.

[28] Tombari “Performance Evaluation of 3D Keypoint Detectors” 


# REFERENCES IN [PAPER](https://github.com/aktumar/3D_reconstruction/blob/main/additional_info/notes/papers/SP_GAN_Sphere_Guided_3D_Shape_Generation_and_Manipulation.md) 

<details>
  <summary>List of papers</summary>
  <pre>
[1] Kfir Aberman, Oren Katzir, Qiang Zhou, Zegang Luo, Andrei Sharf, Chen Greif, Baoquan Chen, and Daniel Cohen-Or. 2017. Dip transform for 3D shape reconstruction. ACM Transactions on Graphics (SIGGRAPH) 36, 4 (2017), 79:1–79:11. 
[2] Panos Achlioptas, Olga Diamanti, Ioannis Mitliagkas, and Leonidas J. Guibas. 2018. Learning representations and generative models for 3D point clouds. In Proceedings of International Conference on Machine Learning (ICML). 40–49. 
[3] Mohammad Samiul Arshad and William J. Beksi. 2020. A progressive conditional generative adversarial network for generating dense and colored 3D point clouds. In International Conference on 3D Vision (3DV). 
[4] Ruojin Cai, Guandao Yang, Hadar Averbuch-Elor, Zekun Hao, Serge Belongie, Noah Snavely, and Bharath Hariharan. 2020. Learning gradient fields for shape generation. In European Conference on Computer Vision (ECCV). 
[5] Angel X. Chang, Thomas Funkhouser, Leonidas J. Guibas, Pat Hanrahan, Qixing Huang, Zimo Li, Silvio Savarese, Manolis Savva, Shuran Song, Hao Su, et al. 2015. ShapeNet: An information-rich 3D model repository. arXiv preprint arXiv:1512.03012 (2015). 
[6] Zhiqin Chen and Hao Zhang. 2019. Learning implicit fields for generative shape modeling. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 5939–5948. 
[7] Yu Deng, Jiaolong Yang, and Xin Tong. 2021. Deformed Implicit Field: Modeling 3D Shapes with Learned Dense Correspondence. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 
[8] Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio. 2016. Density estimation using real NVP. In International Conference on Learning Representations (ICLR). 
[9] Anastasia Dubrovina, Fei Xia, Panos Achlioptas, Mira Shalah, Raphaël Groscot, and Leonidas J. Guibas. 2019. Composite shape modeling via latent space factorization. In IEEE International Conference on Computer Vision (ICCV). 8140–8149. 
[10] Vincent Dumoulin, Jonathon Shlens, and Manjunath Kudlur. 2017. A learned representation for artistic style. In International Conference on Learning Representations (ICLR). 
[11] Rinon Gal, Amit Bermano, Hao Zhang, and Daniel Cohen-Or. 2020. MRGAN: MultiRooted 3D Shape Generation with Unsupervised Part Disentanglement. arXiv preprint arXiv:2007.12944 (2020). 
[12] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative adversarial nets. In Conference on Neural Information Processing Systems (NeurIPS). 2672–2680. 
[13] Thibault Groueix, Matthew Fisher, Vladimir G. Kim, Bryan C. Russell, and Mathieu Aubry. 2018. A papier-mâché approach to learning 3D surface generation. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 216–224. 
[14] Kaiwen Guo, Feng Xu, Tao Yu, Xiaoyang Liu, Qionghai Dai, and Yebin Liu. 2017. Realtime geometry, albedo, and motion reconstruction using a single RGB-D camera. ACM Transactions on Graphics (SIGGRAPH) 36, 3 (2017), 32:1–32:13. 
[15] Rana Hanocka, Gal Metzer, Raja Giryes, and Daniel Cohen-Or. 2020. Point2Mesh: A Self-Prior for Deformable Meshes. ACM Transactions on Graphics (SIGGRAPH) 39, 4 (2020), 126:1–126:12. 
[16] Le Hui, Rui Xu, Jin Xie, Jianjun Qian, and Jian Yang. 2020. Progressive point cloud deconvolution generation network. In European Conference on Computer Vision (ECCV). 
[17] Tero Karras, Samuli Laine, and Timo Aila. 2019. A style-based generator architecture for generative adversarial networks. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 4401–4410. 
[18] Hyeongju Kim, Hyeonseung Lee, Woo Hyun Kang, Joun Yeop Lee, and Nam Soo Kim. 2020. SoftFlow: Probabilistic framework for normalizing flow on manifolds. In Conference on Neural Information Processing Systems (NeurIPS). 
[19] Roman Klokov, Edmond Boyer, and Jakob Verbeek. 2020. Discrete point flow networks for efficient point cloud generation. In European Conference on Computer Vision (ECCV). 
[20] Vladimir A. Knyaz, Vladimir V Kniaz, and Fabio Remondino. 2018. Image-to-voxel model translation with conditional adversarial networks. In European Conference on Computer Vision (ECCV). 
[21] Xiao Li, Yue Dong, Pieter Peers, and Xin Tong. 2017. Modeling surface appearance from a single photograph using self-augmented convolutional neural networks. ACM Transactions on Graphics (SIGGRAPH) 36, 4 (2017), 45:1–45:11. 
[22] Shi-Lin Liu, Hao-Xiang Guo, Hao Pan, Pengshuai Wang, Xin Tong, and Yang Liu. 2021. Deep Implicit Moving Least-Squares Functions for 3D Reconstruction. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 
[23] Matthew Loper, Naureen Mahmood, Javier Romero, Gerard Pons-Moll, and Michael J. Black. 2015. SMPL: A skinned multi-person linear model. ACM Transactions on Graphics (SIGGRAPH Asia) 34, 6 (2015), 248:1–248:16. 
[24] Xudong Mao, Qing Li, Haoran Xie, Raymond Y.K. Lau, Zhen Wang, and Stephen Paul Smolley. 2017. Least squares generative adversarial networks. In IEEE International Conference on Computer Vision (ICCV). 2794–2802. 
[25] Lars Mescheder, Michael Oechsle, Michael Niemeyer, Sebastian Nowozin, and Andreas Geiger. 2019. Occupancy networks: Learning 3D reconstruction in function space. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 4460–4470. 
[26] Kaichun Mo, Paul Guerrero, Li Yi, Hao Su, Peter Wonka, Niloy Mitra, and Leonidas J. Guibas. 2019. StructureNet: Hierarchical graph networks for 3D shape generation. ACM Transactions on Graphics (SIGGRAPH Asia) 38, 6 (2019), 242:1–242:19. 
[27] Kaichun Mo, He Wang, Xinchen Yan, and Leonidas J. Guibas. 2020. PT2PC: Learning to generate 3D point cloud shapes from part tree conditions. In European Conference on Computer Vision (ECCV). 
[28] Jeong Joon Park, Peter Florence, Julian Straub, Richard Newcombe, and Steven Lovegrove. 2019. DeepSDF: Learning continuous signed distance functions for shape representation. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 165–174. 
[29] Charles R. Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas. 2017a. PointNet: Deep learning on point sets for 3D classification and segmentation. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 652–660. 
[30] Charles R. Qi, Li Yi, Hao Su, and Leonidas J. Guibas. 2017b. PointNet++: Deep hierarchical feature learning on point sets in a metric space. In Conference on Neural Information Processing Systems (NeurIPS). 5099–5108. 
[31] Sameera Ramasinghe, Salman Khan, Nick Barnes, and Stephen Gould. 2019. SpectralGANs for high-resolution 3D point-cloud generation. In IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). 8169–8176. 
[32] Edgar Schonfeld, Bernt Schiele, and Anna Khoreva. 2020. A U-Net based discriminator for generative adversarial networks. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 8207–8216. 
[33] Dong Wook Shu, Sung Woo Park, and Junseok Kwon. 2019. 3D point cloud generative adversarial network based on tree structured graph convolutions. In IEEE International Conference on Computer Vision (ICCV). 3859–3868. 
[34] Ayan Sinha, Asim Unmesh, Qixing Huang, and Karthik Ramani. 2017. SurfNet: Generating 3D shape surfaces using deep residual networks. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 6040–6049. 
[35] Edward J. Smith and David Meger. 2017. Improved adversarial systems for 3D object generation and reconstruction. In Conference on Robot Learning. PMLR, 87–96. 
[36] Yongbin Sun, Yue Wang, Ziwei Liu, Joshua Siegel, and Sanjay Sarma. 2020. PointGrow: Autoregressively learned point cloud generation with self-attention. In The IEEE Winter Conference on Applications of Computer Vision (WACV). 61–70. 
[37] Michael Waechter, Mate Beljan, Simon Fuhrmann, Nils Moehrle, Johannes Kopf, and Michael Goesele. 2017. Virtual rephotography: Novel view prediction error for 3D reconstruction. ACM Transactions on Graphics 36, 1 (2017), 8:1–8:11. 
[38] Nanyang Wang, Yinda Zhang, Zhuwen Li, Yanwei Fu, Wei Liu, and Yu-Gang Jiang. \2018. Pixel2Mesh: Generating 3D mesh models from single RGB images. In European Conference on Computer Vision (ECCV). 52–67. 
[39] Yue Wang, Yongbin Sun, Ziwei Liu, Sanjay E. Sarma, Michael M. Bronstein, and Justin M. Solomon. 2019. Dynamic graph CNN for learning on point clouds. ACM Transactions on Graphics 38, 5 (2019), 146:1–146:12.
[40] Jiajun Wu, Yifan Wang, Tianfan Xue, Xingyuan Sun, Bill Freeman, and Josh Tenenbaum. 2017. MarrNet: 3D shape reconstruction via 2.5D sketches. In Conference on Neural Information Processing Systems (NeurIPS). 540–550. 
[41] Jiajun Wu, Chengkai Zhang, Tianfan Xue, Bill Freeman, and Josh Tenenbaum. 2016. Learning a probabilistic latent space of object shapes via 3D generative-adversarial modeling. In Conference on Neural Information Processing Systems (NeurIPS). 82–90. 
[42] Rundi Wu, Yixin Zhuang, Kai Xu, Hao Zhang, and Baoquan Chen. 2020. PQ-NET: A generative part Seq2Seq network for 3D shapes. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 829–838. 
[43] Zhirong Wu, Shuran Song, Aditya Khosla, Fisher Yu, Linguang Zhang, Xiaoou Tang, and Jianxiong Xiao. 2015. 3D ShapeNets: A deep representation for volumetric shapes. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 1912–1920. 
[44] Bo Yang, Stefano Rosa, Andrew Markham, Niki Trigoni, and Hongkai Wen. 2018. Dense 3D object reconstruction from a single depth view. IEEE Transactions Pattern Analysis & Machine Intelligence 41, 12 (2018), 2820–2834. 
[45] Guandao Yang, Xun Huang, Zekun Hao, Ming-Yu Liu, Serge Belongie, and Bharath Hariharan. 2019. PointFlow: 3D point cloud generation with continuous normalizing flows. In IEEE International Conference on Computer Vision (ICCV). 4541–4550. 
[46] Kangxue Yin, Zhiqin Chen, Hui Huang, Daniel Cohen-Or, and Hao Zhang. 2019. LOGAN: Unpaired shape transform in latent overcomplete space. ACM Transactions on Graphics (SIGGRAPH Asia) 38, 6 (2019), 198:1–198:13. 
[47] Kangxue Yin, Hui Huang, Daniel Cohen-Or, and Hao Zhang. 2018. P2P-Net: Bidirectional point displacement net for shape transform. ACM Transactions on Graphics (SIGGRAPH) 37, 4 (2018), 152:1–152:13. 
[48] Wentao Yuan, Tejas Khot, David Held, Christoph Mertz, and Martial Hebert. 2018. PCN: Point completion network. In International Conference on 3D Vision (3DV). 728–737. 
[49] Zerong Zheng, Tao Yu, Yixuan Wei, Qionghai Dai, and Yebin Liu. 2019. DeepHuman: 3D human reconstruction from a single image. In IEEE International Conference on Computer Vision (ICCV). 7739–7749. 
[50] Silvia Zuffi, Angjoo Kanazawa, David Jacobs, and Michael J. Black. 2017. 3D Menagerie: modeling the 3D shape and pose of animals. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 5524–5532.
  </pre>
 </details>

# REFERENCES IN [OPEN3D](http://www.open3d.org/docs/release/)

<details>
  <summary>List of papers</summary>
  <pre>
[1][Bernardini1999] Bernardini and J. Mittleman and HRushmeier and C. Silva and G. Taubin: The ball-pivoting algorithm for surface reconstruction, IEEE transactions on visualization and computer graphics, 5(4), 349-359, 1999
[2][BeslAndMcKay1992] Paul J. Besl and Neil D. McKay, A Method for Registration of 3D Shapes, PAMI, 1992.
[3][ChenAndMedioni1992] Chen and G. G. Medioni, Object modelling by registration of multiple range images, Image and Vision Computing, 10(3), 1992.
[4][Choi2015] Choi, Q.-Y. Zhou, and V. Koltun, Robust Reconstruction of Indoor Scenes, CVPR, 2015.
[5][Curless1996] Curless and M. Levoy. A volumetric method for building complex models from range images. In SIGGRAPH, 1996.
[6][Edelsbrunner1983] Edelsbrunner and D. G. Kirkpatrick and R. Seidel: On the shape of a set of points in the plane, IEEE Transactions on Information Theory, 29 (4): 551–559, 1983
[7][Ester1996] Ester and H.-P. Kriegel and J Sander and X. Xu, A density-based algorithm for discovering clusters in large spatial databases with noise, KDD, 1996.
[8][Katz2007] Katz and A. Tal and R. Basri, Direct visibility of point sets, SIGGRAPH, 2007.
[9][Kazhdan2006] Kazhdan and M. Bolitho and H. Hoppe: Poisson surface reconstruction, Eurographics, 2006.
[10][Loop1987] Loop: Smooth Subdivision Surfaces Based on Triangles, M.S. Mathematics thesis, University of Utah, 1987
[11][LorensenAndCline1987] Lorensen and H. E. Cline, Marching cubes: A high resolution 3d surface construction algorithm, ACM Computer Graphics, 1987
[12][Newcombe2011] Newcombe, S. Izadi, O. Hilliges, D. Molyneaux, D. Kim, A. J. Davison, P. Kohli, J. Shotton, S. Hodges, and A. Fitzgibbon. KinectFusion: Real-time dense surface mapping and tracking. In ISMAR, 2011.
[13][Park2017] Park, Q.-Y. Zhou, and V. Koltun, Colored Point Cloud Registration Revisited, ICCV, 2017.
[14][Rasu2009] Rusu, N. Blodow, and M. Beetz, Fast Point Feature Histograms (FPFH) for 3D registration, ICRA, 2009.
[15][Rusinkiewicz2001] Rusinkiewicz and M. Levoy. Efficient variants of the ICP algorithm. In 3-D Digital Imaging and Modeling, 2001.
[16][Silberman2012] Silberman, D. Hoiem, P. Kohli and R. Fergus, Indoor Segmentation and Support Inference from RGBD Images, ECCV, 2012.
[17][Song2015] Song, S. Lichtenberg, and J. Xiao, SUN RGB-D: A RGB-D Scene Understanding Benchmark Suite, CVPR, 2015.
[18][SorkineAndAlexa2007] Sorkine and M. Alexa, As-rigid-as-possible surface modeling, Symposium on Geometry processing, 2007.
[19][Steinbrucker2011] Steinbrucker, J. Sturm, and D. Cremers, Real-time visual odometry from dense RGB-D images, In ICCV Workshops, 2011.
[20][Strum2012] Sturm, N. Engelhard, F. Endres, W. Burgard and D. Cremers, A Benchmark for the Evaluation of RGB-D SLAM Systems, IROS, 2012.
[21][Taubin1995] Taubin: Curve and surface smoothing without shrinkage, ICCV, 1995.
[22][Zhou2014] Q.-Y. Zhou, and V. Koltun, Color Map Optimization for 3D Reconstruction with Consumer Depth Cameras, SIGGRAPH, 2014.
[23][Zhou2016] Q.-Y. Zhou, J. Park, and V. Koltun, Fast Global Registration, ECCV, 2016.
[24][Babin2019] Babin, P. Giguère and F. Pomerleau: Analysis of Robust Functions for Registration Algorithms, ICRA, 2019.
[25][Segal2009] Segal, D. Haehnel and S. Thrun: Generalized-icp, RSS, 2009.
[26][Dong2021] Dong, Y. Lao, M. Kaess and V. Koltun: ASH: A Modern Framework for Parallel Spatial Hashing in 3D Perception, arXiv, 2021.
  </pre>
 </details>
